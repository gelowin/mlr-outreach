---
title: "mlr3 Workshop"
author: "Jakob Richter"
date: "September 27, 2019"
output: html_document
---

# mlr3 Workshop

## mlr3 building blocks

### Read The dataset and remove unsuitable columns

```{r}
library(data.table)
# Read data and convert strings to factors (as most learners cant handle string columns)
titanic = fread("https://gist.githubusercontent.com/jakob-r/e97e4174534c1d6a3fc95758c6cdc290/raw/fb4795eeb40c03663837a89cf2f97cece52345a2/train.csv", na.strings = "", stringsAsFactors = TRUE)
titanic_pred = fread("https://gist.githubusercontent.com/jakob-r/e97e4174534c1d6a3fc95758c6cdc290/raw/fb4795eeb40c03663837a89cf2f97cece52345a2/test.csv", na.strings = "", stringsAsFactors = TRUE)
str(titanic)

# remove columns that are not directly suitable for prediction
remove_columns = c("PassengerId", "Name", "Ticket", "Cabin")
titanic = titanic[, !(colnames(titanic) %in% remove_columns), with = FALSE]
titanic_pred = titanic_pred[, !(colnames(titanic_pred) %in% remove_columns), with = FALSE]

# convert target column to factor (classification)
titanic[, Survived := as.factor(Survived)]

# build second data.table without columns that contain NAs
na_cols = sapply(colnames(titanic_pred), function(x) any(is.na(titanic[[x]])) || any(is.na(titanic_pred[[x]])))
na_cols = names(na_cols)[na_cols] # extract the names of cols with NAs
titanic_nona = titanic[, !(colnames(titanic) %in% na_cols), with = FALSE]
titanic_nona_pred = titanic_pred[, !(colnames(titanic_pred) %in% na_cols), with = FALSE]
```

### Define an mlr3 Task

```{r}
# if mlr3 is not installed, run the following line:
# remotes::install_github("mlr-org/mlr3verse")
#library(mlr3verse)
#FIXME
lapply(c("~/gits/paradox/", "~/gits/mlr3misc", "~/gits/mlr3", "~/gits/mlr3learners/", "~/gits/mlr3tuning/", "~/gits/mlr3pipelines/"), devtools::load_all)

titanic_tsk = TaskClassif$new(id = "titanic", backend = titanic, target = "Survived")
titanic_tsk

titanic_nona_tsk = TaskClassif$new(id = "titanic_nona", backend = titanic_nona, target = "Survived")
titanic_nona_tsk
```

### Define an mlr3 Learner

Define a logisitc regression learner
```{r}
# Check available learners
mlr_learners
# get more informations from the tabular data
as.data.table(mlr_learners)

lrn = mlr_learners$get("classif.log_reg") # get item from learners directory
lrn = lrn("classif.log_reg") # shorter way
```

### Train the Learner on the Task

Train the previously defined learner on the `titanic_tsk` task.
```{r}
lrn$train(task = titanic_nona_tsk)
```

The learner now stores the model:
```{r}
class(lrn$model)
summary(lrn$model)
```

### Make Predictions

Use the learner that now stores the model to predict the label on the `titanic.pred` data.
```{r}
pred = lrn$predict_newdata(task = titanic_nona_tsk, newdata = titanic_nona_pred)
(pred_dt = as.data.table(pred))
table(pred_dt$response)
```
As `titanic_nona_pred` has no labeled observations we can not calculate the performance.

This can only be done on the training data.

Define a split for the training data:
```{r}
n = titanic_nona_tsk$nrow
train_inds = sample(seq_len(n), size = round(n * 0.66))
test_inds = setdiff(seq_len(n), train_inds)
```

Now we can predict on data with known labels and calculate various performance measures:
```{r}
lrn$predict_type
lrn$predict_type = "prob" # change predict type to probabilities

lrn$train(task = titanic_nona_tsk, row_ids = train_inds)
pred = lrn$predict(task = titanic_nona_tsk, row_ids = test_inds)
mlr_measures
msrs = lapply(c("classif.acc", "classif.auc", "time_train"), msr)
pred$score(measures = msrs)
```

## Resampling

To automate the test train split we can use resample.
First use a resampling method that generates one split like in our manual example before.
```{r}
rds = rsmp("cv")
rds$param_set$values
```
Now use a 5-fold cross-validation:
```{r}
rds$param_set$values$folds = 5
res = resample(task = titanic_nona_tsk, learner = lrn, resampling = rds)
res$score(msrs)
res$aggregate(msrs)
```

## Benchmarking

Benchmark 3 Learners on the `titanic.tsk.nona` and the `iris.task`.
The first learner should be `classif.kknn`.
The second learner should be `classif.kknn` as well but with another hyperparameter setting (e.g. `k = 1`).
Hint: You need to change the id for the benchmark function!
The third one can be chosen freely.
Hint: Use `listLearners(titanic.tsk)` to show possible choices for the task.
```{r}
set.seed(123)

# show learners with properties (again)
as.data.table(mlr_learners)
# experiments with learners that can not handle NAs
design_nona = benchmark_grid(
  tasks = titanic_nona_tsk, 
  learners = lapply(c("classif.log_reg", "classif.kknn", "classif.ranger"), lrn), 
  resamplings = rds)
design_with_na = benchmark_grid(
  tasks = titanic_tsk, 
  learners = lapply(c("classif.xgboost", "classif.rpart"), lrn), 
  resamplings = rds)
design_complete = rbind(design_nona, design_with_na)
res = benchmark(design = design_complete)
mlr3viz::autoplot(res)
```

## Tuning

We want to tune rpart decision tree

```{r}
lrn_rpart = lrn("classif.rpart")
lrn_rpart$param_set
par_set = ParamSet$new(params = list(
  lrn_rpart$param_set$params$cp,
  ParamInt$new(id = "minsplit", lower = 1, upper = 40)
))

mlr_terminators
term_secs = term("clock_time")
term_secs$param_set
term_secs$param_set$values$secs = 3

mlr_tuners
tune_rs = tnr("random_search")

rpart_tuned = AutoTuner$new(learner = lrn_rpart, resampling = rsmp("cv"), measures = msr("classif.acc"), tune_ps = par_set, terminator = term_secs, tuner = tune_rs)

rsmpl_res = resample(titanic_tsk, rpart_tuned, rds, store_models = TRUE)
rsmpl_res$learners[[1]]$model$tuning_instance$result$tune_x
rsmpl_res$learners[[2]]$model$tuning_instance$result$tune_x

res2 = benchmark(design = benchmark_grid(titanic_tsk, rpart_tuned, rds))
res$combine(res2)
mlr3viz::autoplot(res)
```

