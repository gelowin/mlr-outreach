---
title: "Reproducible machine learning workflows"
subtitle: ""
author: "Jakob Richter"
output:
  xaringan::moon_reader:
    lib_dir: libs
    seal: false
    css: 
      - libs/css/theme.css
      - libs/css/extra.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r, include = FALSE}
CHAR_WIDTH = 82
FIG_WIDTH = 9
FIG_HEIGHT = 4

# remotes::install_github("mlr-org/mlr3tuning@19a9a6bf15f984f0e3efdeb162b80fe189e18621")
# remotes::install_github("mlr-org/mlr3@8bc7039fddf3f866339fdf28fc26a7977095c478"

library(paradox)
library(mlr3)
library(magrittr)
options(htmltools.dir.version = FALSE, width=CHAR_WIDTH)
requireNamespace("fansi")
# remotes::install_github("ropenscilabs/icon")
options(
  crayon.enabled = TRUE,
  datatable.print.class = FALSE,
  datatable.print.keys = FALSE,
  width = CHAR_WIDTH
)
knitr::opts_chunk$set(
  comment = NA,
  tidy.opts=list(width.cutoff=CHAR_WIDTH),
  eval = TRUE,
  width = CHAR_WIDTH,
  fig.height = FIG_HEIGHT,
  fig.width = FIG_WIDTH,
  fig.align = "center",
  dev = "svg",
  out.width = "90%",
  cache = FALSE # because it does not work wiht mlr3/R6
)
lgr::get_logger("mlr3")$set_threshold("warn")
```

class: middle left hide-count

<img src="https://raw.githubusercontent.com/mlr-org/mlr/master/man/figures/logo_navbar.png">

.avatars[

<img src="avatars/michel.jpg", max.width = "100%">
<img src="avatars/bernd.jpg", max.width = "100%">
<img src="avatars/jakob.jpg", max.width = "100%">
<img src="avatars/patrick.jpg", max.width = "100%">
<img src="avatars/martin.jpg", max.width = "100%">

]

.talk-meta[
.talk-title[
# Reproducible machine learning workflows
]

.talk-author[
Michel Lang, Bernd Bischl, **Jakob Richter**, **Patrick Schratz**, Martin Binder
]

.talk-location.i[
whyR conference, Warsaw
]

.talk-date.i[
September 27th, 2019
]
]

---

# What is machine learning?

Supervised 
* **Classification**
  * Binary
  * Multiclass
* **Regression**
* Survival (Time To Event)

Unsupervised
* Clustering

---

# What is a machine learning pipeline?

```{r fig_pipelines, echo = FALSE}
knitr::include_graphics("assets/ml-workflow.png", dpi = 30)
```

`r icon::fa("question-circle")` Why are pipelines necessary?  

`r icon::fa("exclamation-circle")` Gives reproducible process that can be validated (through nested cross-validation).

---

# Machine Learning in R

The **good** news:

- CRAN serves hundreds of packages for machine learning

- Many packages for single specific ML-methods
  - `randomForest`, `ranger`
  - `e1070::svm`
  - `kknn`
  - `xgboost`
  - ...
- Often compliant to the unwritten interface definition:

  ```r
  model = fit(target ~ ., data = train.data, ...)
  predictions = predict(model, newdata = test.data, ...)
  ```

---

# Machine Learning in R

The **bad** news:
- Some packages' API is "just different"

- Functionality is always package or model-dependent, even though the procedure might be general

- Capabilities are often not clearly documented
  - "Can this method handle missing/categorical values?"
  
- ML workflow not standardized in R
  - Cross-Validation
  - Hyperparameter Tuning
  - Self implementations are error prone

---

# Motivation: (old) mlr

- Unified interface for the basic building blocks: **tasks**, **learners**,
  **hyperparameters**.
  
- Simplifying repetitive tasks:
  - cross-validation
  - hyperparameter tuning
  - comparison of different methods
  - parallelization  
  
- Project homepage: https://github.com/mlr-org/mlr
- 8-10 main developers
  - even more contributors
  - 5 GSOC projects since 2015
  
- About 30K lines of code, 8K lines of unit tests

---

# What (old) mlr became

Meta framework for everything machine learning (visualization, tuning, feature selection, preprocessing, bagging, ensembles, ...)

* Monolithic package
* Interfaces > 150 learners  
  `r icon::fa("arrow-right")` Dependencies (direct / recursive): 119 / 1436  
  `r icon::fa("arrow-right")` Unit tests take > 2h  
  `r icon::fa("arrow-right")` Package developers changed their API and (unknowingly) broke mlr  
* High barrier for new contributors

* S3 reaches its limitations in larger software projects
* Many specialized and "hard to find" functions `getBMRAggrPerformances()`
* Only works on in-memory data
* No nested parallelization

---

# mlr3

Overcome limitations of S3 with the help of **R6**  
* Truly object-oriented (OO): data and methods together
* Inheritance
* Reference semantics
  
Embrace **data.table**, both for arguments and for internal data structures  
* Fast operations for tabular data
* Better support for list columns to arrange complex objects in a tabular structure
* Reference semantics
  
Be **light on dependencies**. Direct and recursive dependencies:  
* `R6`, `data.table`, `Metrics`, `lgr`
* Some self-maintained packages (`backports`, `checkmate`, ...)

---

# Consequences

* steeper learning curve to learn mlr3

* multiple packages for different functionality
  * mlr3learners
  * mlr3pipelines
  * mlr3tuning
  * mlr3filters
  * mlr3viz
  * ...
  
* easier extendable
  * inherit classes and overwrite functionality

---
class: inverse, center, middle

# mlr3

---

# Building Blocks

```{r fig_building_blocks, echo = FALSE}
knitr::include_graphics("assets/ml_abstraction_colors.svg.png", dpi = 50)
```

---

# Tasks

`r icon::fa("arrow-right")` Create your own task

```{r}
TaskClassif$new("iris", iris, target = "Species")
```
    
`r icon::fa("arrow-right")` Retrieve a predefined task from the task dictionary

```{r}
mlr_tasks
task = mlr_tasks$get("iris")
```

---

# Learner

`r icon::fa("arrow-right")` Retrieve a predefined learner from the learner dictionary

```{r}
mlr_learners
```

`r icon::fa("info-circle")` More learners are available after loading `mlr3learners`.

```{r}
learner = lrn("classif.rpart")
learner
```

---

# Learner

`r icon::fa("arrow-right")` Querying and setting hyperparameters

```{r}
# query
learner$param_set
# set
learner$param_set$values = list(xval = 0, cp = 0.1)
```
    
---

# Learner

`r icon::fa("arrow-right")` Training
```{r}
task = tsk("iris")
learner$train(task, row_ids = seq(1, to = 150, by = 2))
```

`r icon::fa("info-circle")` This changes the learner in-place; the model is now stored inside the learner.

`r icon::fa("arrow-right")` Accessing the learner model
```{r}
learner$model
```

---

# Learner

`r icon::fa("smile")` Unified interface, to acess *feature importance*, *selected features* etc. for all learners. 

```{r}
learner$importance()
learner$selected_features()
```

---

# Prediction

`r icon::fa("arrow-right")` Generate predictions or confusion matrices

```{r}
p = learner$predict(task, row_ids = seq(2, to = 150, by = 2))
head(as.data.table(p), 3)
```

```{r}
p$confusion
```

---

# Measure

`r icon::fa("arrow-right")` Retrieve a predefined measure from the measure dictionary

```{r}
(measure = mlr_measures$get("classif.acc"))
mlr_measures
```

---

# Measure

`r icon::fa("arrow-right")` Calculate performance
```{r}
p$score(measure)
```

Also for multiple measures:
```{r}
p$score(list(measure, msr("time_train")))
```

---

# Resample

`r icon::fa("arrow-right")` Automate train/test splitting and predict with *resampling*.

```{r}
mlr_resamplings
resampling = rsmp("cv", folds = 3)
rr = resample(task, learner, resampling)
```

---

# Resample


```{r}
rr$score() 
```

```{r}
rr$aggregate() 
```

`r icon::fa("info-circle")` The default measure for classif tasks is the *classification error*.

---

# Recap: Building Blocks

```{r fig_building_blocks, echo = FALSE}
```

---

# Dictionaries

Dictionaries store often used objects.

|Dictionary|Helper|  |
|:---------|:-----|--|
|`mlr_tasks`|`tsk()`|Example tasks (iris, spam, ...)|
|`mlr_task_generators`|`tgen()`|Synthetic task generators|
|`mlr_learners`|`lrn()`|learners|
|`mlr_measures`|`msr()`|measures (acc, auc, mse, ...)|
|`mlr_resamplings`|`rsmp()`|resampling strategies (cv, holdout, bootstrap, ...)|

`r icon::fa("info-circle")` Dictionaries can get populated by add-on packages (e.g. `mlr3learners`).

---

# Recap: Example Train/Test

```{r, include = FALSE}
library(mlr3)
set.seed(1)
```

```{r}
# Create learning task
task_iris = TaskClassif$new(id = "iris", backend = iris, 
  target = "Species")

# Load learner from dictionary
learner = lrn("classif.rpart")

# Set learner hyperparameter
learner$param_set$values$cp = 0.01

# Create train/test split
train_set = sample(task_iris$nrow, 0.8 * task_iris$nrow)
test_set = setdiff(seq_len(task_iris$nrow), train_set)

# Train the model
learner$train(task_iris, row_ids = train_set)

# Predict data
prediction = learner$predict(task_iris, row_ids = test_set)
```

---

# Example Train/Test (cont.)

```{r}
prediction
# calculate performance
prediction$confusion
prediction$score(msr("classif.acc"))
```

---

# Recap: Example Resample

`r icon::fa("arrow-right")` Resampling Object

.font25[
```{r}
cv3 = rsmp("cv", folds = 3)
```

Splits into train/test are efficiently stored and can be accessed with `$train_set(i)` and `$test_set(i)`.

`r icon::fa("arrow-right")` Resample a **regression tree** on the "Boston housing" data using a **3-fold CV**

```{r}
# string -> object conversion via dictionary
rr = resample(tsk("boston_housing"), lrn("regr.rpart"), cv3)
```

`r icon::fa("arrow-right")` Aggregated performance

```{r}
rr$aggregate(msr("regr.mse"))
```
]

---
class: inverse, center, middle

# Benchmarking

---

# Benchmarking

`r icon::fa("info-circle")` `benchmark()` runs `resample()` on multiple learners and  tasks

`r icon::fa("arrow-right")` A sensible choice is usually the combination of all components in an exhaustive grid:

```{r benchmark1_design}
design = benchmark_grid(
  tasks = list(tsk("iris"), tsk("spam")), resamplings = rsmp("cv"),
  learners = list(lrn("classif.featureless"), lrn("classif.rpart"))
)
design
```

---

# Benchmarking (cont.)

`r icon::fa("arrow-right")` Execute `benchmark()` on the defined design

```{r benchmark1}
bmr = benchmark(design, store_models = TRUE)
bmr
```

---

# Benchmarking (cont.)

`r icon::fa("arrow-right")` Calculate aggregated performance measure

```{r}
aggr = bmr$aggregate(msr("classif.acc"))
aggr[, 3:7]
```

---

# Benchmarking (cont.)

`r icon::fa("arrow-right")` Retrieve objects from the `BenchmarkResult`:

```{r}
# ResampleResult from 2nd configuration in the design 
# (rpart on iris)

rr = bmr$resample_result(2)

# confusion matrix
rr$prediction()$confusion
```

```{r}
# Average feature importance
sapply(rr$data$learner, function(x) x$importance()) %>% 
  apply(1, mean)
```

---
class: inverse, center, middle

# Tuning

---

# Tuning

* Algorithms: 
  - _Grid Search_
  - _Random Search_ 
  - _Simulated Annealing_

* In process
  - _Bayesian Optimization_
  - _Iterated F-racing_
  - _EAs_

* Budget via class `Terminator`
  - iterations
  - performance threashold
  - model runtime and wallclock time

* Nested resampling via class `AutoTuner`

---

# Tuning

```{r at_resample}
library(mlr3learners)
library(mlr3tuning)

ps = ParamSet$new(list(
  ParamInt$new("min.node.size", lower = 1, upper = 10),
  ParamInt$new("mtry", lower = 10, upper = 50)
))

at = AutoTuner$new(
  learner = lrn("classif.ranger"),
  resampling = rsmp("cv", folds = 3),
  measures = msr("classif.acc"),
  tune_ps = ps, 
  terminator = term("evals", n_evals = 2), 
  tuner = tnr("random_search")
)
resample(tsk("spam"), learner = at, rsmp("holdout"))
```

---

# `AutoTuner` in Benchmark

.pull-left[
`r icon::fa("arrow-right")` Compare tuned learner vs. default learner:

```{r at_benchmark, eval = TRUE}
design = benchmark_grid(
  tasks = tsk("spam"), 
  learners = list(
    at, 
    lrn("classif.ranger")
  ), 
  resamplings = rsmp("cv", 
    folds = 5))
bmr = benchmark(design)
```

`r icon::fa("info-circle")` _mlr3viz_ package contains `autoplot()` functions for some `mlr3` objects.

```{r fig_at_benchmark, eval = TRUE, fig.keep='none'}
library(mlr3viz)
autoplot(bmr)
```


]

.pull-right[
```{r fig_at_benchmark, fig.width=0.5*FIG_WIDTH, echo = FALSE}
```
]


---
class: inverse, center, middle

# mlr3pipelines

---

# Pipelines

```{r, comment="", results="asis", echo =FALSE}
# setup chunk only!
old.hooks = fansi::set_knit_hooks((knitr::knit_hooks))
options(crayon.enabled = TRUE)
```

So far *mlr3* just modeled this part:
<div style="
    border: solid #ff0000 10px;
    width: 189px;
    height: 75px;
    position: fixed;
    left: 324px;
    top: 416px;"></div>
```{r fig_pipelines, echo = FALSE, out.width="80%"}
```

Step 1: Use pipelines for preprocessing (feature extraction/selection, missing data imputation etc.).  
Step 2: Use pipelines for ensemble models.

---

# Preprocessing Pipelines

We can put preprocessing *PipeOps* in front of a Learner

.center[
![pipeline example](assets/mlr3pipelines-slide12.svg)
]

```{r}
library(mlr3pipelines)

mlr_pipeops
```

---

# Preprocessing Pipelines

Use **`%>>%`** to connect *PipeOps*:

```{r, warning=FALSE}
scale = po("scale") 
encode = po("encode")
impute = po("imputemean")
learner = po("learner", lrn("classif.kknn", scale = FALSE))
grph = scale %>>% encode %>>% impute %>>% learner #<<
(glrn = GraphLearner$new(grph))
```

---

# Access Hyperparameters of PipeOps

Like learners, *PipeOps* have hyperparameters controling their behavior.

Change hyperparameter values in ...
1. construction of *PipeOp*
  ```{r, results='hide'}
  po("scale", scale = FALSE)
  ```
2. *PipeOp* before building *Graph*
  ```{r, results='hide'}
  scale$param_set$values$scale = FALSE
  ```
3. *Graph* before building *GraphLearner*
  ```{r, results='hide'}
  grph$pipeops$scale$param_set$values$scale = FALSE
  ```
4. *GraphLearner*  
  `r icon::fa("info-circle")` Note the prefix of the *PipeOp* name!
  ```{r}
  glrn$param_set$values$scale.scale = FALSE #<<
  ```

---

# Train Graph Learner

`r icon::fa("arrow-right")` Train the *GraphLearner* like every other mlr3 learner:

```{r}
tsk = tsk("iris")
glrn$train(tsk, row_ids = seq(1, 150, by = 2))
```

Most *PipeOps* have parameters (just like a trained model), that are learned from the training data:

.center[
![pipeline parameters](assets/mlr3pipelines-slide2.svg)
]
---

# Train Graph Learner

`r icon::fa("info-circle")` The scaling factors `center` $\mu$ and `scale` $\sigma$ are learned on the *training* data, and applied to new data that passes through the *PipeOp* for *prediction*.

```{r}
glrn$model$scale[c("center",  "scale")]
p = glrn$predict(tsk, row_ids = seq(2, 150, by = 2))
```

---

# Train Graph Learner (cont.)

1. `glrn$train()` passes the training data through all _PipeOps_.  
   Each *PipeOp* transforms the data and saves the transformation parameter.
   
2. `glrn$predict()` passes the new data through all _PipeOps_  
   Each *PipeOp* applies the transformation with the stored transformation parameters.  
   This ensures, that new data is transformed exactly as the training data.

.center[
![trained graph learner](assets/mlr3pipelines-slide20.svg)
]

---

# PipeOp Parameters

`r icon::fa("arrow-right")` Resample the complete preprocessing pipeline:

```{r}
rr = resample(tsk, glrn, rsmp("cv"), store_models = TRUE)
```

Each model is scaled according to its training data:

```{r}
rr$learners[[1]]$model$scale$center
rr$learners[[10]]$model$scale$center
```

`r icon::fa("info-circle")` Remember: Transforming the data before crossvalidating skews results. Transforming the data independently for training and test leads to wrong results!

---

# Tune Parameters of PipeOps

.pull-left[
Access *PipeOp* hyperparameter through param with its prefix in the *GraphLearner*.

```{r}
ps = ParamSet$new(list(
  ParamLgl$new("scale.scale"), #<<
  ParamInt$new("classif.kknn.k",
    lower = 1, upper = 3)
))
```

`r icon::fa("info-circle")` *Grid search* terminates automatically, hence a termination criterion is optional.

```{r}
instance = TuningInstance$new(
  task = tsk("iris"),
  learner = glrn,
  resampling = rsmp("cv", folds = 3),
  measures = msr("classif.acc"),
  param_set = ps,
  terminator = term("none")
)
```
]

.pull-right.code85[
```{r}
tt = tnr("grid_search")
tt$tune(instance)
instance$archive()[, .(learner_id, classif.acc)]
instance$result$tune_x
```
]

---

# Advanced Pipelines

Pipelines become exiting, once you can modify the path of the data using these *PipeOps*:

<div style="display: block;width: 150px;height: 130px;position: absolute;background-color: #FAFAFACC; left: 200px"></div>
![PipeOps](assets/mlr3pipelines-slide6.svg)

**Branching** and **Copy** have multiple outputs, so the next *PipeOps* needs multiple inputs.
To create these...

---

# Branching

1. Combine multiple *PipeOps* one below each other:  
  .img60.center[![mlr3pipelines union](assets/mlr3pipelines-slide4.svg)]
2. Replicate a *PipeOp* N times one below each other:  
  .img60.center[![mlr3pipelines replicate](assets/mlr3pipelines-slide5.svg)]  
  `r icon::fa("info-circle")` This is especially useful to build bagged learners in combination with *model averaging* (`regravg` or `classifavg`) afterwards.
  
---

# Control Branching through Parameters

.pull-left[
```{r fig_branch, fig.keep='none'}
library(mlr3filters)

pca = po("pca", rank. = 2)
filter = po("filter", flt("variance"), 
  filter.nfeat = 2)

branch = po("branch",
  c("pca", "filter", "nop"))

union = gunion(
  list(pca, filter, po("nop")))

grph = branch %>>% 
  union %>>% 
  po("unbranch") %>>%
  po("learner", lrn("classif.kknn"))

plot(grph)
```
]

.pull-right[
```{r fig_branch, echo=FALSE, fig.width=0.5*FIG_WIDTH, fig.height=1.5*FIG_HEIGHT}
```
]

---

# Tune Branching

.pull-left[
```{r tune_branch}
glrn = GraphLearner$new(grph)

ps = ParamSet$new(list(
  ParamFct$new("branch.selection",
    levels = c("pca", "filter", "nop")),
  ParamInt$new("classif.kknn.k",
    lower = 1, upper = 3)
))

instance = TuningInstance$new(
  task = tsk("iris"),
  learner = glrn,
  resampling = rsmp("cv", folds = 3),
  measures = msr("classif.acc"),
  param_set = ps,
  terminator = term("none")
)
```
]

.pull-right[
```{r tune_branch_res}
tt = tnr("grid_search")
tt$tune(instance)
instance$result$tune_x
instance$result$perf
```

`r icon::fa("info-circle")` Tuning hyperparameters of *PipeOps* that *can* be active needs dependent parameters. 
Check the [mlr3book paradox chapter](https://mlr3book.mlr-org.com/paradox.html).
]

---
# Build Ensemble with PipeOps

.pull-left[
Instead of branching we can *copy*, to use multiple *PipeOps* on the same data:

```{r graph_copy, fig.keep='none'}
grph = po("copy", 2) %>>% 
  gunion(list(
    po("learner_cv", lrn("regr.rpart")),
    po("nop")
  )) %>>%
  po("featureunion") %>>%
  po("learner", lrn("regr.lm"))
plot(grph)
```
]

.pull-right[
```{r graph_copy, echo=FALSE, fig.width=0.5*FIG_WIDTH, fig.height=1.5*FIG_HEIGHT}
```
]

---

# Compare Pipe to normal Learner

```{r}
glrn = GraphLearner$new(grph)

design = benchmark_grid(
  tasks = tsk("mtcars"), 
  learners = list(glrn, lrn("regr.lm")), 
  resamplings = rsmp("cv"))

bmr = benchmark(design = design, store_models = TRUE)

bmr$aggregate()[, -(1:3)]
```

---

# _PipeOps_ not covered by this tutorial

* Ensembles with `subsample`
* Feature generation with `mutate`
* Feature manipulation with `colapply`
* Feature selection with `select`
* Class balancing with `classbalancing`
* Prediction combining with `classifavg` and `regravg`
* and more.

`r icon::fa("info-circle")` Check the [mlr3book pipelines chapter](https://mlr3book.mlr-org.com/pipelines.html) for exhaustive explanations and more examples.

---

class: inverse, center, middle

# mlr3 Advanced Usage

---

# Internal Data Structure

All result objects (`resample()`, `benchmark()`, tuning, ...) share the same structure:

```{r}
as.data.table(rr)
```

---

# Internal Data Structure

#### Combining `R6` and `data.table`
* Not the objects are stored, but pointers to them

* Inexpensive to work on:
  * `rbind()`: copying R6 objects &wedgeq; copying pointers
  * `cbind()`: `data.table()` over-allocates columns, no copies
  * `[i, ]`: lookup row (possibly hashed), create a list of pointers
  * `[, j]`: direct access to list element

---

# Control of Execution

`r icon::fa("arrow-right")` Parallelization
```{r, eval = FALSE}
future::plan("multicore")
benchmark(grid)
```

* runs each resampling iteration as a job

* also allows nested resampling (although not needed here)

---

# Control of Execution

`r icon::fa("arrow-right")`  Encapsulation

```{r, eval = FALSE}
learner$encapsulate = c(train = "callr", predict = "callr")
```

* Spawns a separate R process to train the learner

* Learner may segfault without tearing down the master session

* Logs are captured

* Possibility to have a fallback learner to create predictions

---

# Out-of-memory Data

Task stores data in a `DataBackend`:
  * `DataBackendDataTable`: Default backend for dense data (in-memory)
  
  * `DataBackendMatrix`: Backend for sparse numerical data (in-memory)
  
  * `mlr3db::DataBackendDplyr`: Backend for many DBMS (out-of-memory)
  
  * `DataBackendCbind`: Combine backends thorugh `task$cbind(backend)` (virtual)
  
  * `DataBackendRbind`: Combine backends thorugh `task$rbind(backend)` (virtual)
    
---

# Out-of-memory Data

Backends are immutable
  * Filtering rows or selecting columns just modifies the "view" on the data
  * Multiple tasks can share the same backend
    
Example: 
1. Interface a read-only MariaDB with `DataBackendDplyr`
1. Add generated features via `DataBackendDataTable`

---

# Resources

<iframe width="560" height="315" src="https://www.youtube.com/embed/wsP2hiFnDQs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

- [CI Status](https://github.com/mlr-org/mlr3/wiki/CI-Status)
- [Extension packages](https://github.com/mlr-org/mlr3/wiki/Extension-Packages)
- [mlr3book](https://mlr3book.mlr-org.com)

Want to contribute?  
[mlr3.mlr-org.com](https://mlr3.mlr-org.com)



```{r xaringanthemer, include=FALSE}
library(xaringanthemer) # remotes::install_github("gadenbuie/xaringanthemer")
duo_accent(
  outfile = ("libs/css/theme.css"),
  primary_color = "#03638e", secondary_color = "#f8f8f8",
  inverse_background_color = "#23373b",
  text_font_google     = google_font("Roboto"),
  header_font_google   = google_font("Oswald"),
  code_font_google     = google_font("Roboto Mono"),
  code_font_size = "0.75em",
  header_h1_font_size = "45px",
  text_bold_color = "#000000",
  title_slide_background_color = "#002733",
  link_color = "#eb1455",
  text_font_size = "22px",
  header_color = "#002733",
  padding = "0em 2em 1em 2em"
)

extra_css = list(
    ".hide-count .remark-slide-number, .inverse .remark-slide-number" = list(
      display = "none"
    ),
    ".inverse h1" = list(
      "font-size" = "100px",
      "color" = "white"
    ),
    ".remark-slide-content h1" = list(
      "margin-top" = "10px"
    ),
    ".code85" = list(
      "font-size" = "0.85em"
    ),
    ".font20" = list(
      "font-size" = "20px"
    ),
    ".avatars" = list(
      "width" = "100px",
      "white-space" = "nowrap",
      "left" = "300px",
      "top" = "30px",
      "position" = "absolute"
    ),
    ".img60 img"= list(
      "max-width"= "60%"
    ),
    "div.remark-slide-content>img, .center>img" = list(
      "margin" = "auto",
      "display" = "block"
    ),
    # somehow indented lines are treated as highlighted, this is a dirty bugfix
    "code:not(.r) .remark-code-line-highlighted:not(.r)" = list(
      "background-color" = "inherit"    
    ),
    "code:not(.r) .remark-code-line" = list(
      "color" = "#448e08"
    ),
    ".pull-left" = list(
      "float" = "left",
      "width" = "50%",
      "margin-left" = "-20px",
      "padding-right" = "27px"
    ),
    
    ".pull-right" = list(
      "float" = "right",
      "width" = "50%",
      "margin-right" = "-20px"
    ),
    "pre" = list(
      "white-space" = "pre-wrap  /* Since CSS 2.1 */",
      "white-space" = "-moz-pre-wrap /* Mozilla, since 1999 */",
      "white-space" = "-pre-wrap  /* Opera 4-6 */",
      "white-space" = "-o-pre-wrap   /* Opera 7 */",
      "word-wrap" = "break-word  /* Internet Explorer 5.5+ */",
      "margin-top" = "0.5em",
      "margin-bottom" = "0.5em"
    ),
    # Code in lists should use less whitespace
    "li pre" = list(
      "margin" = "0"
    ),
    "li p" = list(
      "margin-top" = "0.2em",
      "margin-bottom" = "0.2em"
    )
)
file.remove("libs/css/extra.css") #somehow write_extra_css appends the content
write_extra_css(css = extra_css, outfile = "libs/css/extra.css")
```

