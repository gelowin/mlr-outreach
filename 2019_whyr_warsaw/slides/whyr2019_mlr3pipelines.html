<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>foo</title>
    <meta charset="utf-8" />
    <meta name="author" content="" />
    <link href="libs/font-awesome/css/fontawesome-all.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="assets/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="assets/css/extra.css" type="text/css" />
    <link rel="stylesheet" href="assets/css/tachyons.min.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




&lt;STYLE type='text/css' scoped&gt;
PRE.fansi SPAN {padding-top: .25em; padding-bottom: .25em};
&lt;/STYLE&gt;

class: middle left hide-count

&lt;img src="https://raw.githubusercontent.com/mlr-org/mlr/master/man/figures/logo_navbar.png"&gt;

.avatars[

&lt;img src="avatars/michel.jpg", max.width = "100%"&gt;
&lt;img src="avatars/bernd.jpg", max.width = "100%"&gt;
&lt;img src="avatars/jakob.jpg", max.width = "100%"&gt;
&lt;img src="avatars/patrick.jpg", max.width = "100%"&gt;
&lt;img src="avatars/martin.jpg", max.width = "100%"&gt;

]

.talk-meta[
.talk-title[
# mlr3pipelines
]

.talk-author[
Michel Lang, Bernd Bischl, **Jakob Richter**, **Patrick Schratz**, Martin Binder
]

.talk-location.i[
whyR conference, Warsaw
]

.talk-date.i[
September 27th, 2019
]
]

---
class: inverse, center, middle

# mlr3pipelines

---

# Pipelines

So far *mlr3* just modeled this part:
&lt;div style="
    border: solid #ff0000 10px;
    width: 189px;
    height: 75px;
    position: fixed;
    left: 324px;
    top: 416px;"&gt;&lt;/div&gt;


Step 1: Use pipelines for preprocessing (feature extraction/selection, missing data imputation etc.).
Step 2: Use pipelines for ensemble models.

---

# Preprocessing Pipelines

We can put preprocessing *PipeOps* in front of a Learner

![pipeline example](assets/mlr3pipelines-slide12.svg)

.code85[

```r
library(mlr3pipelines)

mlr_pipeops
```

```
# &lt;DictionaryPipeOp&gt; with 38 stored values
# Keys: boxcox, branch, chunk, classbalancing, classifavg, colapply, copy, encode,
#   encodelmer, featureunion, filter, histbin, ica, imputehist, imputemean, imputemedian,
#   imputenewlvl, imputesample, kernelpca, learner, learner_cv, missind, modelmatrix,
#   mutate, nop, pca, quantilebin, regravg, removeconstants, scale, scalemaxabs,
#   scalerange, select, smote, spatialsign, subsample, unbranch, yeojohnson
```
]

---

# Preprocessing Pipelines

Use **`%&gt;&gt;%`** to connect *PipeOps*:


```r
scale = po("scale") 
encode = po("encode")
impute = po("imputemean")
learner = po("learner", lrn("classif.kknn", scale = FALSE))
*grph = scale %&gt;&gt;% encode %&gt;&gt;% impute %&gt;&gt;% learner
(glrn = GraphLearner$new(grph))
```

```
# &lt;GraphLearner:scale.encode.imputemean.classif.kknn&gt;
# * Model: -
# * Parameters: encode.method=one-hot, classif.kknn.scale=FALSE
# * Packages: stats
# * Predict Type: response
# * Feature types: logical, integer, numeric, character, factor, ordered, POSIXct
# * Properties: importance, missings, multiclass, oob_error, selected_features, twoclass,
#   weights
```

---

# Access Hyperparameters of PipeOps

Like learners, *PipeOps* have hyperparameters controling their behavior.

.code75[

Change hyperparameter values in ...
1. construction of *PipeOp*
  
  ```r
  po("impute", method_num = "sample")
  ```
2. *PipeOp* before building *Graph*
  
  ```r
  impute$param_set$values$method_num = "sample"
  ```
3. *Graph* before building *GraphLearner*
  
  ```r
  grph$pipeops$impute$param_set$values$method_num = "sample"
  ```
4. *GraphLearner*
  <i class="fas  fa-info-circle "></i> Note the prefix of the *PipeOp* name!
  
  ```r
  *glrn$param_set$values$impute.method_num = "sample"
  ```
]

---

# Train Graph Learner

<i class="fas  fa-arrow-right "></i> Train the *GraphLearner* like every other mlr3 learner:

.code75[

```r
tsk = tsk("iris")
glrn$train(tsk, row_ids = seq(1, 150, by = 2))
```
]

Most *PipeOps* have parameters (just like a trained model), that are learned from the training data:

![pipeline parameters](assets/mlr3pipelines-slide2.svg)
---

# Train Graph Learner

<i class="fas  fa-info-circle "></i> The scaling factors `center` `\(\mu\)` and `scale` `\(\sigma\)` are learned on the *training* data, and applied to new data that passes through the *PipeOp* for *prediction*.


```r
glrn$model$scale[c("center",  "scale")]
```

```
# $center
# Petal.Length  Petal.Width Sepal.Length  Sepal.Width 
#     3.776000     1.218667     5.840000     3.064000 
# 
# $scale
# Petal.Length  Petal.Width Sepal.Length  Sepal.Width 
#    1.7829402    0.7907734    0.8058905    0.4354681
```

```r
p = glrn$predict(tsk, row_ids = seq(2, 150, by = 2))
```

---

# Train Graph Learner (cont.)

1. `glrn$train()` passes the training data through all _PipeOps_.  
   Each *PipeOp* transforms the data and saves the transformation parameter.
   
2. `glrn$predict()` passes the new data through all _PipeOps_  
   Each *PipeOp* applies the transformation with the stored transformation parameters.  
   This ensures, that new data is transformed exactly as the training data.

---

# Train Graph Learner (cont.)

![trained graph learner](assets/mlr3pipelines-slide20.svg)

---

# PipeOp Parameters

.code75[
<i class="fas  fa-arrow-right "></i> Resample the complete preprocessing pipeline:


```r
rr = resample(tsk, glrn, rsmp("cv"), store_models = TRUE)
```

Each model is scaled according to its training data:


```r
rr$learners[[1]]$model$scale$center
```

```
# Petal.Length  Petal.Width Sepal.Length  Sepal.Width 
#     3.730370     1.178519     5.807407     3.054074
```

```r
rr$learners[[10]]$model$scale$center
```

```
# Petal.Length  Petal.Width Sepal.Length  Sepal.Width 
#     3.754815     1.204444     5.867407     3.065926
```
]

<i class="fas  fa-info-circle "></i> Remember: Transforming the data before crossvalidating skews results. Transforming the data independently for training and test leads to wrong results!

---

# Tune Parameters of PipeOps

.pull-left.code75[
We access the *PipeOp* hyperparameter through the parameter with its prefix in the *GraphLearner*.


```r
ps = ParamSet$new(list(
  ParamLgl$new("scale.scale"),
  ParamInt$new("classif.kknn.k",
    lower = 1, upper = 3)
))
```

<i class="fas  fa-info-circle "></i> *Grid search* terminates once the grid is completed, hence a termination criterion is optional.


```r
instance = TuningInstance$new(
  task = tsk("iris"),
  learner = glrn,
  resampling = rsmp("cv", folds = 3),
  measures = msr("classif.acc"),
  param_set = ps,
  terminator = term("none")
)
```
]

.pull-right.code55[

```r
tt = tnr("grid_search")
tt$tune(instance)
instance$archive()[, .(learner_id, classif.acc)]
```

```
#                              learner_id classif.acc
# 1: scale.encode.imputemean.classif.kknn   0.9333333
# 2: scale.encode.imputemean.classif.kknn   0.9333333
# 3: scale.encode.imputemean.classif.kknn   0.9600000
# 4: scale.encode.imputemean.classif.kknn   0.9600000
# 5: scale.encode.imputemean.classif.kknn   0.9600000
# 6: scale.encode.imputemean.classif.kknn   0.9333333
```

```r
instance$result
```

```
# $tune_x
# $tune_x$scale.scale
# [1] FALSE
# 
# $tune_x$classif.kknn.k
# [1] 2
# 
# 
# $params
# $params$encode.method
# [1] "one-hot"
# 
# $params$classif.kknn.scale
# [1] FALSE
# 
# $params$scale.scale
# [1] FALSE
# 
# $params$classif.kknn.k
# [1] 2
# 
# 
# $perf
# classif.acc 
#        0.96
```
]

---

# Advanced Pipelines

Pipelines become exiting, once you can modify the path of the data using these *PipeOps*:

&lt;div style="display: block;width: 150px;height: 130px;position: absolute;background-color: #FAFAFACC; left: 200px"&gt;&lt;/div&gt;
![PipeOps](assets/mlr3pipelines-slide6.svg)

**Branching** and **Copy** have multiple outputs, so the next *PipeOps* needs multiple inputs.
To create these...

---

# Branching

1. Combine multiple *PipeOps* one below each other:  
  .img70[![mlr3pipelines union](assets/mlr3pipelines-slide4.svg)]
2. Replicate a *PipeOp* N times one below each other:  
  .img70[![mlr3pipelines replicate](assets/mlr3pipelines-slide5.svg)]  
  <i class="fas  fa-info-circle "></i> This is especially useful to build bagged learners in combination with *model averaging* (`regravg` or `classifavg`) afterwards.
  
---

# Control Branching through Parameters

.pull-left.code75[

```r
library(mlr3filters)

pca = po("pca", rank. = 2)
filter = po("filter", flt("variance"), 
  filter.nfeat = 2)

branch = po("branch",
  c("pca", "filter", "nop"))

union = gunion(
  list(pca, filter, po("nop")))

grph = branch %&gt;&gt;% 
  union %&gt;&gt;% 
  po("unbranch") %&gt;&gt;%
  po("learner", lrn("classif.kknn"))

plot(grph)
```
]

.pull-right[
&lt;img src="whyr2019_mlr3pipelines_files/figure-html/fig_branch-1.svg" width="90%" style="display: block; margin: auto;" /&gt;
]

---

# Tune Branching

.pull-left.code75[

```r
glrn = GraphLearner$new(grph)

ps = ParamSet$new(list(
  ParamFct$new("branch.selection",
    levels = c("pca", "filter", "nop")),
  ParamInt$new("classif.kknn.k",
    lower = 1, upper = 3)
))

instance = TuningInstance$new(
  task = tsk("iris"),
  learner = glrn,
  resampling = rsmp("cv", folds = 3),
  measures = msr("classif.acc"),
  param_set = ps,
  terminator = term("none")
)
```
]

.pull-right.code55[

```r
tt = tnr("grid_search")
tt$tune(instance)
instance$result
```

```
# $tune_x
# $tune_x$branch.selection
# [1] "pca"
# 
# $tune_x$classif.kknn.k
# [1] 3
# 
# 
# $params
# $params$branch.selection
# [1] "pca"
# 
# $params$pca.rank.
# [1] 2
# 
# $params$variance.filter.nfeat
# [1] 2
# 
# $params$variance.na.rm
# [1] TRUE
# 
# $params$classif.kknn.k
# [1] 3
# 
# 
# $perf
# classif.acc 
#        0.96
```

<i class="fas  fa-info-circle "></i> Tuning hyperparameters of *PipeOps* that *can* be active needs dependent parameters. 
Check the [mlr3book paradox chapter](https://mlr3book.mlr-org.com/paradox.html).
]

---
# Build Ensemble with PipeOps

.pull-left[
Instead of branching we can *copy*, to use multiple *PipeOps* on the same data:

.code75[

```r
grph = po("copy", 2) %&gt;&gt;% 
  gunion(list(
    po("learner_cv", lrn("regr.rpart")),
    po("nop")
  )) %&gt;&gt;%
  po("featureunion") %&gt;&gt;%
  po("learner", lrn("regr.lm"))
plot(grph)
```
]
]

.pull-right[
&lt;img src="whyr2019_mlr3pipelines_files/figure-html/graph_copy-1.svg" width="90%" style="display: block; margin: auto;" /&gt;
]

---

# Compare Pipe to normal Learner

.code75[

```r
glrn = GraphLearner$new(grph)

design = benchmark_grid(
  tasks = tsk("mtcars"), 
  learners = list(glrn, lrn("regr.lm")), 
  resamplings = rsmp("cv"))

bmr = benchmark(design = design, store_models = TRUE)

bmr$aggregate()[, -(1:3)]
```

```
#                                  learner_id resampling_id iters regr.mse
# 1: copy.regr.rpart.nop.featureunion.regr.lm            cv    10 15.50814
# 2:                                  regr.lm            cv    10 12.97293
```
]

---

# _PipeOps_ not covered by this tutorial

* Ensembles with `subsample`
* Feature generation with `mutate`
* Feature manipulation with `colapply`
* Feature selection with `select`
* Class balancing with `classbalancing`
* Prediction combining with `classifavg` and `regravg`
* and more.

<i class="fas  fa-info-circle "></i> Check the [mlr3book pipelines chapter](https://mlr3book.mlr-org.com/pipelines.html) for exhaustive explanations and more examples.

---

# Out-of-memory Data

.font20[
* Task stores data in a `DataBackend`:
    * `DataBackendDataTable`: Default backend for dense data (in-memory)
    * `DataBackendMatrix`: Backend for sparse numerical data (in-memory)
    * `mlr3db::DataBackendDplyr`: Backend for many DBMS (out-of-memory)
    * `DataBackendCbind`: Combine backends thorugh `task$cbind(backend)` (virtual)
    * `DataBackendRbind`: Combine backends thorugh `task$rbind(backend)` (virtual)
    
* Backends are immutable
    * Filtering rows or selecting columns just modifies the "view" on the data
    * Multiple tasks can share the same backend
    
* Example: Interface a read-only MariaDB with `DataBackendDplyr`, add generated features via `DataBackendDataTable`
]

---

# Resources

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/gEW5RxkbQuQ?controls=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;&gt;

- [CI Status](https://github.com/mlr-org/mlr3/wiki/CI-Status)
- [Extension packages](https://github.com/mlr-org/mlr3/wiki/Extension-Packages)
- [mlr3book](https://mlr3book.mlr-org.com)

Want to contribute?  
[mlr3.mlr-org.com](https://mlr3.mlr-org.com)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
